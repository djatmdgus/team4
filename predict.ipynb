{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from konlpy.tag import Mecab\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/Users/um_seun/project6/한국어_단발성_대화_데이터셋.xlsx'\n",
    "\n",
    "data = pd.read_excel(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-05 16:23:44.211383: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-07-05 16:23:44.211512: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "model = None\n",
    "with open('model.pkl','rb') as pickle_file:\n",
    "    model = pickle.load(pickle_file)\n",
    "\n",
    "tokenizer = None\n",
    "with open('tokenizer.pickle','rb') as pickle_file_tok:\n",
    "    tokenizer = pickle.load(pickle_file_tok)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = df['Sentence']   # Sentence == comment_ori\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emoticon_del(data):\n",
    "    #이모티콘 제거\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    #분석에 어긋나는 불용어구 제외 (특수문자, 의성어)\n",
    "    han = re.compile(r'[ㄱ-ㅎㅏ-ㅣ!?~,\"a-zA-z0-9:.\\n\\r#\\ufeff\\u200d]')\n",
    "\n",
    "    comment_list = []\n",
    "    for i in range(len(data)):\n",
    "        comment_list.append(data['Sentence'].iloc[i])\n",
    "\n",
    "    comment_result = []\n",
    "    for i in comment_list:\n",
    "        tokens = re.sub(emoji_pattern,\"\",str(i))\n",
    "        tokens = re.sub(han,\"\",tokens)\n",
    "        comment_result.append(tokens)\n",
    "    comment_result = pd.DataFrame(comment_result, columns=[\"Sentence\"])\n",
    "    data['Sentence'] = comment_result \n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def token(data):\n",
    "    # 불용어(포함 안 시킬 단어) 처리 \n",
    "    stopwords = ['도', '는', '다', '의', '가', '이', '은', '한', '에', '하', '고', '을', '를', '인', '듯', '과', '와', '네', '들', '듯', '지', '임', '게', '만', '게임', '겜', '되', '음', '면','!', '.', ',', '~', '?', 'ㅡ', 'ㅠ', 'ㅜ','/', ' '] \n",
    "            #'도', '는', '다', '의', '가', '이', '은', '한', '에', '하', '고', '을', '를', '인', '듯', '과', '와', '네', '들', '듯', '지', '임', '게', '만', '게임', '겜', '되', '음', '면',\n",
    "    mecab = Mecab()\n",
    "    \n",
    "    data['tokenized'] = data['Sentence'].apply(mecab.morphs)\n",
    "    data['tokenized'] = data['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])\n",
    "    \n",
    "def lav_1(x):\n",
    "    if x == 0:\n",
    "        return '불안'\n",
    "    if x == 1:\n",
    "        return '당황'\n",
    "    if x == 2:\n",
    "        return '분노'\n",
    "    if x == 3:\n",
    "        return '슬픔'\n",
    "    if x == 4:\n",
    "        return '기쁨'\n",
    "    if x == 5:\n",
    "        return '기쁨'\n",
    "    if x == 6:\n",
    "        return '상처'\n",
    "    \n",
    "\n",
    "def tokenizer_sequences_pad_sequences(data):\n",
    "    max_len = 50\n",
    "    \n",
    "    test_set = tokenizer.texts_to_sequences(data['tokenized'])   # Sentence == comment_ori\n",
    "    pad_test_set = pad_sequences(test_set, maxlen=max_len, padding='post') #패딩 처리\n",
    "    \n",
    "    predict_test_set = model.predict(pad_test_set)          #모델 predict\n",
    "    \n",
    "    classes = np.argmax(predict_test_set, axis = 1)\n",
    "    classs = pd.Series(classes)\n",
    "    \n",
    "    data['predict'] = classs                       \n",
    "    data['predict'] = data['predict'].apply(lav_1)\n",
    "    return data\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#최종\n",
    "def predict(data):\n",
    "    data = emoticon_del(data)\n",
    "    token(data)\n",
    "    data = tokenizer_sequences_pad_sequences(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-05 16:24:24.752557: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-07-05 16:24:25.763633: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-05 16:24:26.027403: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-05 16:24:26.038077: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-05 16:24:26.185970: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-05 16:24:26.194316: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-05 16:24:26.315639: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-05 16:24:26.323443: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-05 16:24:26.445229: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-05 16:24:26.453031: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1207/1207 [==============================] - 74s 60ms/step\n"
     ]
    }
   ],
   "source": [
    "data = predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>언니 동생으로 부르는게 맞는 일인가요</td>\n",
       "      <td>공포</td>\n",
       "      <td>불안</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>그냥 내 느낌일뿐겠지</td>\n",
       "      <td>공포</td>\n",
       "      <td>슬픔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>아직너무초기라서 그런거죠</td>\n",
       "      <td>공포</td>\n",
       "      <td>불안</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>유치원버스 사고 낫다던데</td>\n",
       "      <td>공포</td>\n",
       "      <td>불안</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>근데 원래이런거맞나요</td>\n",
       "      <td>공포</td>\n",
       "      <td>불안</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38589</th>\n",
       "      <td>솔직히 예보 제대로 못하는 데 세금이라도 아끼게 그냥 폐지해라</td>\n",
       "      <td>혐오</td>\n",
       "      <td>분노</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38590</th>\n",
       "      <td>재미가 없으니 망하지</td>\n",
       "      <td>혐오</td>\n",
       "      <td>기쁨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38591</th>\n",
       "      <td>공장 도시락 비우생적임 아르바이트했는데 화장실가성 손도 않씯고 재료 담고 바닥 떨어...</td>\n",
       "      <td>혐오</td>\n",
       "      <td>불안</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38592</th>\n",
       "      <td>코딱지 만한 나라에서 지들끼리 피터지게 싸우는 센징 클래스</td>\n",
       "      <td>혐오</td>\n",
       "      <td>상처</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38593</th>\n",
       "      <td>와이프도 그렇고 댓글 다 볼텐데 이휘재 좀 하차 하라고 전해주세요</td>\n",
       "      <td>혐오</td>\n",
       "      <td>기쁨</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38594 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Sentence Emotion predict\n",
       "0                                   언니 동생으로 부르는게 맞는 일인가요      공포      불안\n",
       "1                                            그냥 내 느낌일뿐겠지      공포      슬픔\n",
       "2                                          아직너무초기라서 그런거죠      공포      불안\n",
       "3                                          유치원버스 사고 낫다던데      공포      불안\n",
       "4                                            근데 원래이런거맞나요      공포      불안\n",
       "...                                                  ...     ...     ...\n",
       "38589                 솔직히 예보 제대로 못하는 데 세금이라도 아끼게 그냥 폐지해라      혐오      분노\n",
       "38590                                        재미가 없으니 망하지      혐오      기쁨\n",
       "38591  공장 도시락 비우생적임 아르바이트했는데 화장실가성 손도 않씯고 재료 담고 바닥 떨어...      혐오      불안\n",
       "38592                  코딱지 만한 나라에서 지들끼리 피터지게 싸우는 센징 클래스       혐오      상처\n",
       "38593               와이프도 그렇고 댓글 다 볼텐데 이휘재 좀 하차 하라고 전해주세요      혐오      기쁨\n",
       "\n",
       "[38594 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['Sentence','Emotion','predict']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "fc546dcb9973d982b4b4dae6662f4996ec0618c166151e42343c5687d53144d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
